data:
  n_samples: 500000       # total synthetic transactions
  fraud_ratio: 0.03      # 3% fraud
  random_state: 42

paths:
  raw_data: "data/raw/transactions.csv"
  processed_data: "data/processed/transactions_features.csv"
  model_dir: "data/models"
  best_model_path: "data/models/best_model.joblib"
  metrics_path: "data/processed/metrics.json"

training:
  test_size: 0.2
  random_state: 42
  target_col: "is_fraud"

models:
  candidates:
    - "logreg"
    - "random_forest"
    - "xgboost"
    - "mlp"
    - "lightgbm"
    - "catboost"
  logreg:
    max_iter: 2000
    solver: "lbfgs"

  random_forest:
    n_estimators: 200
    max_depth: 8
    n_jobs: -1

  xgboost:
    booster: "gbtree"
    max_depth: 6
    learning_rate: 0.1
    n_estimators: 500
    tree_method: "hist"  # for large datasets

  mlp:
    hidden_layers: [128, 64, 32]
    epochs: 10
    batch_size: 4096

  lightgbm:
    num_leaves: 64
    learning_rate: 0.05
    n_estimators: 500

  catboost:
    depth: 8
    learning_rate: 0.1
    n_estimators: 300